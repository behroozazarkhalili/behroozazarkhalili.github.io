<!DOCTYPE html>
<html lang="en">
<head>
<script>


function myOpen() {
var demo = arguments[0];
  var x = document.getElementById(demo);
  if (x.style.display === 'none') {
    x.style.display = 'block';
  } else {
    x.style.display = 'none';
  }
}
</script>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Research website of Behrooz Azarkhalili, a Ph.D.
  student at Stanford Enshallah!">
  <meta name="author" content="God">
  <link rel="shortcut icon" href="/img/favicon.ico" type="image/x-icon">
  <title>Behrooz Azarkhalili</title>

  <!-- CSS -->
        <link rel="stylesheet" href="https://a-slide.github.io/theme/css/bootstrap.flatly.min.css" type="text/css"/>
<link href="https://a-slide.github.io/theme/css/font-awesome.min.css" rel="stylesheet">

    <link href="https://a-slide.github.io/theme/css/pygments/native.css" rel="stylesheet">
    <link href="https://a-slide.github.io/theme/tipuesearch/tipuesearch.css" rel="stylesheet">
        <link href="https://a-slide.github.io/theme/css/typogrify.css" rel="stylesheet">
<link rel="stylesheet" href="https://a-slide.github.io/theme/css/style.css" type="text/css"/>
  <link rel="stylesheet" href="/css/main.css">
  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
  <![endif]-->
</head>
<body>
  <div class="container">

    <div class="row" style="padding:20px">

       <div class="hidden-xs col-sm-3 col-md-2" id="sidebar" role="navigation" style="margin-top:180px">
        <hr>
        <ul class="nav nav-pills nav-stacked">
          <li><a href="#Research Interests">Research Interests</a></li>
          <li><a href="#Projects">Projects</a></li>
          <li><a href="#publications">Publications</a></li>
          <li><a href="#Curriculum Vitae">Curriculum Vitae</a></li>
          <li><a href="blog">Blog</a></li>
        </ul>
      </div>

      <div class="col-xs-12 col-sm-9 col-md-9">

        <div class="row">
          <img src="img/babak.jpeg" class="pull-left" style="margin:20px
          20px 20px 0; height:140px; width:140px; border-radius:100%"/>
          <h2>Ermia (Behrooz) Azarkhalili</h2>
          <p class="lead">
            Data Scientist at Royan Institute<br>
            <br>

            <a href="https://twitter.com/ErmiaBivatan" class="icon">
              <i class="fa fa-twitter fa-lg"></i>
            </a>
            <a href="https://github.com/ErmiaAzarkhalili" class="icon">
              <i class="fa fa-github fa-lg"></i>
            </a>
          </p>
        </div>

        <hr>

        <div class="row" align="justify" style="font-size:14px;">
          <p>
          I am a data scientist at
          <a href="http://royaninstitute.org/">Royan Institute</a>. conducting research on the applications of deep and
machine learning algorithms in bioinformatics subdisciplines like cancer detection, drug
discovery, drug repositioning, personalized medication, and electronic health records. 
          </p>
<p></p>
          <p>
My particular interest is to develop computationally efficient DL methods to resolve problems arising in noisy and high dimensional datasets. The fundamental problem here is to infer reliable conclusions from noisy observations or data, specifically when limited computations and data are available. Collectively with modern settings where the dimensionality of data is high, achieving these twin objectives simultaneously is intricate. It appears that one of the current trends in DL is to resolve the aforementioned problems by implementing probabilistic and statistical modeling techniques. To become an expert in these fields, it is quintessential to possess deep foundations in Bayesian Deep Learning and Generative Probabilistic Models, which are among my main research topics.
</p>
<p></p>
<p>Alongside with Deep Probabilistic Models, I am immensely interested in understanding and developing de-novo Transfer Learning techniques such as Multi-Task Learning (MTL), Sequential Transfer Learning, and Deep Domain Adaptation in NLP and CV, which, for instance, can be applied to question answering (QA), neural machine translation (NMT), object detection and object segmentation. Furthermore, I am enthusiastic to utilize and develop novel attention based on recurrent network models alongside deep contextualized word representations (such as ELMO, BERT, and Transformers) on image or video caption generation for movies scene interpretation or inference from scenes.
</p>
<p></p>
<!--<p>
Currently, I have remotely joined to          
 <a href="https://www.genapsys.com/">GenapSys</a>
           to effectively resolve the DNA sequencing problem by implementing state-of-the-art algorithms of neural networks. Providing the python package to easily implement the DNA sequencing, the primary goal of the project is to revolutionize the DNA sequencing process.
          </p> -->

<p></p>
<p>
I am looking forward to a PhD position in outstanding labs in the USA or Europe. Please kindly ping me if you are intersted in my resume and research background.
</p>
<p>
        <!--  Recently, I have been giving the following talk:
          </p>
          <ul>
            <li>
              <div class="btn-group-xs">
                <strong>What Might Deep Learners Learn From Probabilistic
                  Programming?</strong>
                <a href="/talks/Tran_Probabilistic_Programming.pdf"
                class="btn btn-default">Slides</a>
              </div>
            </li>
          </ul>-->

        </div>
        <div class="row">
          <h3><a name="Research Interests"></a>Research Interests</h3>
          
            <ul style="list-style-type:square;">
                <strong><li>Natural Language Processing (NLP)</li></strong>
                <strong><li>Computrer Vision (CV)</li></strong>
                <strong><li>Deep Probabilistic Learning</li></strong>
                <strong><li>Bioinfromatics</li></strong>
            </ul>
          </p>
        </div>
        <div class="row" align="justify">
          <h3><a name="Projects"></a>Projects</h3>
          <p>
            <ul style="list-style-type:square;font-size:14px;">
                <p>Since 2016, I have joined Royan Institute for Computational Biology as a data scientist to work under the supervision of Dr. Ali Sharifi Zarchi, the member of Scientific Committee in International Informatics Olympiad (IoI) and the Professor of CS department at Sharif University of Technology. At Royan, my efforts were to apply DL techniques to cancer detection problems which have resulted in two first-author papers.</p><li><h4>Status: Active</h4><p style="font-size:14px;"><strong>Understanding Cell Identity Using Deep Neural Networks.</strong><div class="btn-group-xs"><a onclick="myOpen('demo9')" href="javascript:void(0);"
              class="btn btn-default">Detail</a>

             <div  id="demo9" style="display:none;font-size:14px;"><p>
I was the co-first author of the paper <a href="https://www.nature.com/articles/s41598-019-38798-y.">[1]</a>, ” Cell Identity Codes: Understanding Cell Identity from Gene Expression Profiles using Deep Neural Networks ”, which was accepted in Nature Scientific Reports. In this project, we identified a specific structure of deep autoencoders that can encode gene expression profiles (GEP) into a vector of 30 numeric values, which we called the cell identity code (CIC). We also showed that the distinctive values of the CIC are connected to various biological aspects of the cell, such as distinct pathways or biological processes. My contribution was to implement the python code project, analyzing the data and results, and writing the main draft of the paper. In this project, I utilized Tensorflow, Keras, Pytorch, Scikit Learn, and HyperOpt as the main packages to develop the source code.</p></div></div></p></li>
<li><h4>Status: Active</h4><p style="font-size:14px;"><strong>Cancer Detection Using Deep Learning.</strong><div class="btn-group-xs"><a onclick="myOpen('demo8')" href="javascript:void(0);"
              class="btn btn-default">Detail</a>

             <div  id="demo8" style="display:none;font-size:14px;"><p>
In the second paper <a href="https://arxiv.org/abs/1808.02237">[2]</a>, ” DeePathology: Deep Multi-Task Learning for Inferring Molecular Pathology from Cancer Transcriptome ”, which was submitted to ”Nature Scientific Reports”, we introduced a novel architecture of DNNs that was capable of simultaneous inference of various properties of biological samples, through multi-task and transfer learning. Our methodology significantly outperforms prior works and classical machine learning approaches in predicting tissue-of-origin, normal or disease state and cancer type of each sample. We also showed that this system is remarkably robust against noise and missing values. Besides writing the main draft of the paper, I developed a Python source code based on Tensorflow and Keras to resolve this Multi-Task learning problem.</p></div></div></p></li>
<li><h4>Status: In progress</h4><p style="font-size:14px;"><strong>Prediction of Clinical Events Using Deep Contextualized Word Embedings.</strong><div class="btn-group-xs"><a onclick="myOpen('demo7')" href="javascript:void(0);"
              class="btn btn-default">Detail</a>

             <div  id="demo7" style="display:none;font-size:14px;"><p>

I have recently embarked on with Dr. Sharifi Zarchi where we are applying recent innovative NLP concepts and tools including Attention, BERT, GPT2, and ELMO on biomedical and clinical notes to conduct a systematic review of deep learning models for electronic health record (EHR) data, and illustrate various deep learning architectures for analyzing different data sources and their target applications including information extraction and sequential prediction of clinical events. This work resulted in achieving the SOTA results in survival analysis of different cancer types.
</p></div></div>
</br></br>
<p>I have recently embarked on my research with Dr. Mohammad Amin Sadeghi, who has completed his Ph.D. at the CS department at UIUC, in the Computer Vision Laboratory at Tehran University. </p>
</p></li>
<li>
  <h4>Status: In progress</h4>
<p style="font-size:14px;"><strong>Dollar Street: Prediction of Individuals' Income Utilizing the Images of Their Posession.</strong></p><div class="btn-group-xs">
<a onclick="myOpen('demo7')" href="javascript:void(0);" class="btn btn-default">Detail</a>
 <div  id="demo7" style="display:none;font-size:14px;"><p>
</br>In this project, we have been working on the project of predicting income of individuals based on the images of their commodities and possessions. To solve this problem, we are utilizing de nova techniques such as transfer learning, Deep Set, Dimensionality Reduction, Ensemble Methods, and Hyper-Parameter Optimization to estimates families’ income based on the images of their commodities. I was one of the main developer of the project where I implemented python code utilizing Keras, Tensorflow, Scikit Learn, MLEns, and HyperOpt.</p></div></div>
</li>
            </ul>

        </div>
        <div class="row">
          <h3><a name="publications"></a>Publications</h3>
           <h4>Pappers</h4>
           <h5>2019</h5>
          <p>
          <p style="font-size:14px;">
           <strong>Cell Identity Codes: Understanding Cell Identity from Gene Expression Profiles using Deep Neural Networks.</strong></br></p>
  <p style="font-size:13px;">
          Farzad Abdolhosseini, <strong>Behrooz Azarkhalili</strong> (Co-First Author), Abbas Maazallahi, Aryan Kamal, Seyed Abolfazl Motahari, Ali Sharifi-Zarchi & Hamidreza Chitsaz<br>
           <em>Nature Scientific Reports</em>, 2019</p>
           <div class="btn-group-xs">
             <a href="https://arxiv.org/pdf/1806.04863.pdf "
             class="btn btn-default">Paper's Link one</a>
             <a href="https://www.nature.com/articles/s41598-019-38798-y"
             class="btn btn-default">Paper's Link two</a>
             <a href="http://github.com/deepgradient"
              class="btn btn-default">Code</a>
             <a onclick="myOpen('demo1')" href="javascript:void(0);"
              class="btn btn-default">Abstract</a>
             <a onclick="myOpen('demo2')" href="javascript:void(0);"
              class="btn btn-default">BibTex</a>

             <div  id="demo1" style="display:none;;font-size:14px;"><p>Understanding cell identity is an important task in many biomedical areas. Expression patterns of specific marker genes have been used to characterize some limited cell types, but exclusive markers are not available for many cell types. A second approach is to use machine learning to discriminate cell types based on the whole gene expression profiles (GEPs). The accuracies of simple classification algorithms such as linear discriminators or support vector machines are limited due to the complexity of biological systems. We used deep neural networks to analyze 1040 GEPs from 16 different human tissues and cell types. After comparing different architectures, we identified a specific structure of deep autoencoders that can encode a GEP into a vector of 30 numeric values, which we call the cell identity code (CIC). The original GEP can be reproduced from the CIC with an accuracy comparable to technical replicates of the same experiment. Although we use an unsupervised approach to train the autoencoder, we show different values of the CIC are connected to different biological aspects of the cell, such as different pathways or biological processes. This network can use CIC to reproduce the GEP of the cell types it has never seen during the training. It also can resist some noise in the measurement of the GEP. Furthermore, we introduce</p></div>
             <div  id="demo2" style="display:none;"><p>@misc{1806.04863,
Author = {Farzad Abdolhosseini and Behrooz Azarkhalili and Abbas Maazallahi and Aryan Kamal and Seyed Abolfazl Motahari and Ali Sharifi-Zarchi and Hamidreza Chitsaz},
Title = {Cell Identity Codes: Understanding Cell Identity from Gene Expression Profiles using Deep Neural Networks},
Year = {2018},
Eprint = {arXiv:1806.04863},
}</p></div>
           </div>
          </p>
           <h5>2019</h5>
          <p>
<p style="font-size:14px;">
           <strong>A Compressive Sampling Approach To Adaptive Multi-Resolution Approximation of Differential Equations With Random Inputs.</strong></br></p>
<p style="font-size:13px;">
          <strong>Behrooz Azarkhalili</strong><br></p>
           <div class="btn-group-xs">
             <a href="https://arxiv.org/pdf/1307.0483.pdf"
             class="btn btn-default">Paper</a>
             <a href="https://github.com/ErmiaAzarkhalili/"
              class="btn btn-default">Code</a>
             <a onclick="myOpen('demo3')" href="javascript:void(0);"
              class="btn btn-default">Abstract</a>
             <a onclick="myOpen('demo4')" href="javascript:void(0);"
              class="btn btn-default">BibTex</a>

             <div  id="demo3" style="display:none;font-size:14px;"><p>In this paper, a novel method to adaptively approximate the solution to stochastic differential equations, which is based on compressive sampling and sparse recovery, is introduced. The proposed method consider the problem of sparse recovery with respect to multiwavelet basis (MWB) from a small number of random samples to approximate the solution to problems. To illustrate the robustness of developed method, three benchmark problems are studied and the main statistical features of solutions such as the variance and the mean of solutions obtained by the proposed method are compared with the ones obtained from Monte Carlo simulations.</p></div>
             <div  id="demo4" style="display:none;"><p>@misc{1307.0483,
Author = {Behrooz Azarkhalili},
Title = {A Compressive Sampling Approach To Adaptive Multi-Resolution Approximation of Differential Equations With Random Inputs},
Year = {2013},
Eprint = {arXiv:1307.0483},
}
</p></div>
           </div>
          </p>
          </p>
           <h5>2018</h5>
          <p>
<p style="font-size:14px;">
           <strong>DeePathology: Deep Multi-Task Learning for Inferring Molecular Pathology from Cancer Transcriptome.</strong></br></p>
<p style="font-size:13px;">
          <strong>Behrooz Azarkhalili</strong>, Ali Saberi, Hamidreza Chitsaz, Ali Sharifi-Zarchi<br></p>
           <div class="btn-group-xs">
             <a href="https://arxiv.org/pdf/1808.02237.pdf"
             class="btn btn-default">Paper</a>
             <a href="http://github.com/deepgradient"
              class="btn btn-default">Code</a>

             <a onclick="myOpen('demo5')" href="javascript:void(0);"
              class="btn btn-default">Abstract</a>
             <a onclick="myOpen('demo6')" href="javascript:void(0);"
              class="btn btn-default">BibTex</a>

             <div  id="demo5" style="display:none;font-size:14px;"><p>Despite great advances, molecular cancer pathology is often limited to use a small number of biomarkers rather than the whole transcriptome, partly due to the computational challenges. Here, we introduce a novel architecture of DNNs that is capable of simultaneous inference of various properties of biological samples, through multi-task and transfer learning. We employed this architecture on mRNA transcription profiles of 10787 clinical samples from 34 classes (one healthy and 33 different types of cancer) from 27 tissues. Our system significantly outperforms prior works and classical machine learning approaches in predicting tissue-of-origin, normal or disease state and cancer type of each sample. Furthermore, it can predict miRNA transcription profile of each sample, which enables performing miRNA expression research when only mRNA transcriptome data are available. We also show this system is very robust against noise and missing values. Collectively, our results highlight applications of artificial intelligence in molecular cancer pathology and oncological research.</p></div>
             <div  id="demo6" style="display:none;"><p>@misc{1808.02237,
Author = {Behrooz Azarkhalili and Ali Saberi and Hamidreza Chitsaz and Ali Sharifi-Zarchi},
Title = {Inferring Molecular Pathology and micro-RNA Transcriptome from mRNA Profiles of Cancer Biopsies through Deep Multi-Task Learning},
Year = {2018},
Eprint = {arXiv:1808.02237},
}</p></div>
           </div>
          </p>
        <h4>Books</h4>
            <h5>2018</h5>
            <p>
<p style="font-size:14px;">
            <strong>Introduction to Machine Learning (In Persian).</strong></br>            </p>
<p style="font-size:13px;">
            Soheil Kia, <strong>Azarkhalili B.</strong> (Technical Editor)</br> </p>
            </p>
        <h4>Patents</h4>
            <h5>2018</h5>
            <p style="font-size:14px;">
            <strong>Azarkhalili B.</strong>, Methods and systems using deep learning for detecting cancer and other disorders. April 13, 2018 (Filed)</br>
            </p>
        </div>
        <div class="row" align="justify">
            <h3>
                <a name="Curriculum Vitae"></a>Curriculum Vitae
            </h3>
            <p style="font-size:14px;">
                My resume is available upon <a href="mailto:ermiaazarkhalili@gmail.com">request</a>.
            </p>
        </div>
        <!-- <div class="row">
          <h2><a name="publications"></a>Publications</h2>
            <hr>
          <h3>Preprints</h3>
          <p>
          Some of my work is available as
          <a href="http://arxiv.org/a/tran_d_1.html">preprints on arXiv</a>.
          </p>
          <p>
           <strong>Reliable uncertainty estimates in deep neural
             networks using noise contrastive priors</strong><br>
           A prior for neural networks in data space.
           <br>
           Danijar Hafner, <strong>Dustin Tran</strong>, Alex Irpan,
           Timothy Lillicrap, James Davidson<br>
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1807.09289"
             class="btn btn-default">Paper</a>
             <a href="/papers/HafnerTranIrpanLillicrapDavidson2018_poster.pdf"
             class="btn btn-default">Poster</a>
           </div>
          </p>
          <p>
           <strong>TensorFlow Distributions</strong><br>
           A backend for efficient, composable manipulation of
           probability distributions.
           <br>
           Joshua V. Dillon, Ian Langmore, <strong>Dustin
           Tran</strong>, Eugene Brevdo, Srinivas Vasudevan, Dave
           Moore, Brian Patton, Alex Alemi, Matt Hoffman, Rif A.
           Saurous<br>
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1711.10604"
             class="btn btn-default">Paper</a>
           </div>
          </p>
          <p>
            <strong>Expectation propagation as a way of life: A
            framework for Bayesian inference on partitioned
            data</strong><br>
            How to distribute inference with massive data sets and how
            to combine inferences from many data sets.
            <br>
            Andrew Gelman, Aki Vehtari, Pasi Jylänki, Tuomas Sivula,
            <strong>Dustin Tran</strong>, Swupnil Sahai, Paul
            Blomstedt, John P. Cunningham, David Schiminovich,
            Christian Robert<br>
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/1412.4869"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>Edward: A library for probabilistic modeling,
            inference, and criticism</strong><br>
            Everything and anything about probabilistic models.
            <br>
            <strong>Dustin Tran</strong>, Alp Kucukelbir, Adji B. Dieng,
            Maja Rudolph, Dawen Liang, David M. Blei<br>
            <div class="btn-group-xs">
              <a href="https://arxiv.org/abs/1610.09787"
              class="btn btn-default">Paper</a>
              <a href="http://edwardlib.org"
              class="btn btn-default">Website</a>
              <a href="/talks/Tran_Edward.pdf"
              class="btn btn-default">Slides</a>
            </div>
          </p>
          <p>
            <strong>Model criticism for Bayesian causal inference</strong><br>
            How to validate inferences from causal models.
            <br>
            <strong>Dustin Tran</strong>, Francisco J. R. Ruiz, Susan
            Athey, David M. Blei<br>
            <div class="btn-group-xs">
              <a href="http://arxiv.org/abs/1610.09037"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>Stochastic gradient descent methods for estimation with
            large data sets</strong><br>
            Fast and statistically efficient algorithms for
            generalized linear models and M-estimation.
            <br>
            <strong>Dustin Tran</strong>, Panos Toulis, Edoardo M.
            Airoldi<br>
            <em>Journal of Statistical Software</em>, To appear
            <div class="btn-group-xs">
              <a href="http://arxiv.org/abs/1509.06459"
              class="btn btn-default">Paper</a>
              <a href="https://github.com/airoldilab/sgd"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <h3>2018</h3>
          <p>
           <strong>Image Transformer</strong><br>
           An image autoregressive model using only attention.
           <br>
           Niki Parmar, Ashish Vaswani, Jakob Uszkoreit, Lukasz Kaiser, Noam
           Shazeer, Alexander Ku, <strong>Dustin Tran</strong><br>
           <em>International Conference on Machine Learning</em>, 2018
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1802.05751"
             class="btn btn-default">Paper</a>
             <a href="/papers/ParmarVaswaniUszkoreitKaiserShazeerKuTran2018_poster.pdf"
             class="btn btn-default">Poster</a>
           </div>
          </p>
          <p>
           <strong>Implicit causal models for genome-wide association
           studies</strong><br>
           Generative models applied to causality in genomics.
           <br>
           <strong>Dustin Tran</strong>, David M. Blei<br>
           <em>International Conference on Learning Representations</em>, 2018
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1710.10742"
             class="btn btn-default">Paper</a>
             <a href="/papers/TranBlei2018_poster.pdf"
             class="btn btn-default">Poster</a>
             <a href="https://www.youtube.com/watch?v=gi2jZ_bVJuA&index=6&list=PL6_fD5q0zQxshmFJCSBaA5Jglf62Ct4Vm"
             class="btn btn-default">Video</a>
             <a href="/talks/Tran_Genomics.pdf"
             class="btn btn-default">Slides</a>
           </div>
          </p>
          <p>
           <strong>Flipout: Efficient pseudo-independent weight perturbations
           on mini-batches</strong><br>
           How to make weight perturbations in evolution strategies and
           variational BNNs as mini-batch-friendly as activation perturbations
           in dropout and batch norm.
           <br>
           Yeming Wen, Paul Vicol, Jimmy Ba, <strong>Dustin Tran</strong>,
           Roger Grosse<br>
           <em>International Conference on Learning Representations</em>, 2018
           <div class="btn-group-xs">
             <a href="https://arxiv.org/abs/1803.04386"
             class="btn btn-default">Paper</a>
             <a href="https://github.com/tensorflow/probability"
             class="btn btn-default">Code</a>
           </div>
          </p>
          <h3>2017</h3>
          <p>
            <strong>Hierarchical implicit models and likelihood-free
            variational inference</strong><br>
            Combining the idea of implicit densities with hierarchical Bayesian
            modeling and deep neural networks.
            <br>
            <strong>Dustin Tran</strong>, Rajesh Ranganath, David M.
            Blei<br>
            <em>Neural Information Processing Systems</em>, 2017
            <div class="btn-group-xs">
              <a href="/papers/TranRanganathBlei2017.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/TranRanganathBlei2017_poster.pdf"
              class="btn btn-default">Poster</a>
              <a href="http://dustintran.com/blog/deep-and-hierarchical-implicit-models"
              class="btn btn-default">Blog Article</a>
            </div>
          </p>
          <p>
            <strong>Variational inference via $\chi$-upper bound
            minimization</strong><br>
            Overdispersed approximations and upper bounding
            the model evidence.
            <br>
            Adji B. Dieng, <strong>Dustin Tran</strong>, Rajesh
            Ranganath, John Paisley, David M. Blei<br>
            <em>Neural Information Processing Systems</em>, 2017
            <div class="btn-group-xs">
              <a href="/papers/BoussoTranRanganathPaisleyBlei2017.pdf"
              class="btn btn-default">Paper</a>
              <a href="https://github.com/blei-lab/edward"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <p>
            <strong>Comment, "Fast approximate inference for
            arbitrarily large semiparametric regression models via
            message passing"</strong><br>
            The role of message passing in automated inference.
            <br>
            <strong>Dustin Tran</strong>, David M. Blei<br>
            <em>Journal of the American Statistical Association</em>,
            112(517):156–158, 2017
            <div class="btn-group-xs">
              <a href="http://arxiv.org/abs/1609.05615"
              class="btn btn-default">Paper</a>
              <a href="http://dustintran.com/blog/discussion-of-fast-approximate-inference"
              class="btn btn-default">Blog Article</a>
            </div>
          </p>
          <p>
            <strong>Automatic differentiation variational inference</strong><br>
            An automated tool for black box variational inference,
            available in Stan.
            <br>
            Alp Kucukelbir, <strong>Dustin Tran</strong>, Rajesh Ranganath,
            Andrew Gelman, David M. Blei<br>
            <em>Journal of Machine Learning Research</em>, 18(14):1–45, 2017
            <div class="btn-group-xs">
              <a href="/papers/KucukelbirTranRanganathGelmanBlei2017.pdf"
              class="btn btn-default">Paper</a>
              <a href="https://github.com/stan-dev/stan"
              class="btn btn-default">Code</a>
              <a href="/talks/Tran_Automating.pdf"
              class="btn btn-default">Slides</a>
            </div>
          </p>
          <p>
            <strong>Deep probabilistic programming</strong><br>
            How to build a language with rich compositionality for
            modeling and inference.
            <br>
            <strong>Dustin Tran</strong>, Matthew D. Hoffman, Rif A.
            Saurous, Eugene Brevdo, Kevin Murphy, David M. Blei<br>
            <em>International Conference on Learning Representations</em>, 2017
            <div class="btn-group-xs">
              <a href="/papers/TranHoffmanSaurousBrevdoMurphyBlei2017.pdf"
              class="btn btn-default">Paper</a>
              <a href="http://edwardlib.org/iclr2017"
              class="btn btn-default">Website</a>
              <a href="/papers/TranHoffmanMurphyBrevdoSaurousBlei2017_poster.pdf"
              class="btn btn-default">Poster</a>
              <a href="/talks/Tran_Edward.pdf"
              class="btn btn-default">Slides</a>
            </div>
          </p>
          <h3>2016</h3>
          <p>
            <strong>Operator variational inference</strong><br>
            How to formalize computational and statistical tradeoffs in variational inference.
            <br>
            Rajesh Ranganath, Jaan Altosaar, <strong>Dustin
            Tran</strong>, and David M. Blei<br>
            <em>Neural Information Processing Systems</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/RanganathAltosaarTranBlei2016.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/RanganathAltosaarTranBlei2016_poster.pdf"
              class="btn btn-default">Poster</a>
            </div>
          </p>
          <p>
            <strong>Hierarchical variational models</strong><br>
            A Bayesian formalism for constructing expressive
            variational families.
            <br>
            Rajesh Ranganath, <strong>Dustin Tran</strong>, David M.
            Blei<br>
            <em>International Conference on Machine Learning</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/RanganathTranBlei2016.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/RanganathTranBlei2016_poster.pdf"
              class="btn btn-default">Poster</a>
            </div>
          </p>
          <p>
            <strong>Spectral M-estimation with application to hidden
            Markov models</strong><br>
            Applying M-estimation for sample efficiency and robustness
            in moment-based estimators.
            <br>
            <strong>Dustin Tran</strong>, Minjae Kim, Finale Doshi-Velez<br>
            <em>Artificial Intelligence and Statistics</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/TranKimDoshi-Velez2016.pdf"
              class="btn btn-default">Paper</a>
            </div>
          </p>
          <p>
            <strong>Towards stability and optimality in stochastic gradient
            descent</strong><br>
            A stochastic gradient method combining numerical stability
            and statistical efficiency.
            <br>
            Panos Toulis, <strong>Dustin Tran</strong>, Edoardo M.
            Airoldi<br>
            <em>Artificial Intelligence and Statistics</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/ToulisTranAiroldi2016.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/ToulisTranAiroldi2016_poster.pdf"
              class="btn btn-default">Poster</a>
              <a href="https://github.com/airoldilab/sgd"
              class="btn btn-default">Code</a>
            </div>
          </p>
          <p>
            <strong>The variational Gaussian process</strong><br>
            A powerful variational model that can universally
            approximate any posterior.
            <br>
            <strong>Dustin Tran</strong>, Rajesh Ranganath, David M.
            Blei<br>
            <em>International Conference on Learning Representations</em>, 2016
            <div class="btn-group-xs">
              <a href="/papers/TranRanganathBlei2016.pdf"
              class="btn btn-default">Paper</a>
              <a href="/talks/Tran_Variational.pdf"
              class="btn btn-default">Slides</a>
            </div>
          </p>
          <h3>2015</h3>
          <p>
            <strong>Copula variational inference</strong><br>
            Posterior approximations using copulas, which find
            meaningful dependence between latent variables.
            <br>
            <strong>Dustin Tran</strong>, David M. Blei, Edoardo M.
            Airoldi<br>
            <em>Neural Information Processing Systems</em>, 2015
            <div class="btn-group-xs">
              <a href="/papers/TranBleiAiroldi2015.pdf"
              class="btn btn-default">Paper</a>
              <a href="/papers/TranBleiAiroldi2015_poster.pdf"
              class="btn btn-default">Poster</a> 
            </div>-->
          </p>
        </div>

      </div>

    </div>

    <hr>

    <footer>
    &nbsp;
    </footer>

  </div>


  <!-- JavaScript -->
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/js/bootstrap.min.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'] ],
        processEscapes: true
      }
    });
  </script>
  <script type="text/javascript"
     src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
  <script type="text/javascript" src="/js/main.js"></script>
</body>
</html>
